{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79321b1e",
   "metadata": {},
   "source": [
    "# Faster R_CNN for Object Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import io\n",
    "from shutil import copyfile\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0f3b2",
   "metadata": {},
   "source": [
    "## Importing the necessary Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset \n",
    "data_Set = \"data_Set_satellite_imagery.csv\"\n",
    "annotated_dataset = \"annotations_satellite_imagery.csv\"\n",
    "class_description_dataset = \"class_description_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_boxable = pd.read_csv(data_Set)\n",
    "print(images_boxable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_box = pd.read_csv(annotated_dataset)\n",
    "print(annotations_box.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf905501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions = pd.read_csv(class_description_dataset)\n",
    "print(class_descriptions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383b59b",
   "metadata": {},
   "source": [
    "## plot_bbox - Function which is being annotating from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(img_id): \n",
    "    img_url_exact_loc = images_boxable.loc[images_boxable['file_name'] == img_id]\n",
    "    img_changed = img_url_exact_loc['file_name']\n",
    "    img_changed_list = list(img_changed)\n",
    "    img_changed_str = \" \".join(map(str,img_changed_list))\n",
    "    img=io.imread(img_changed_str)\n",
    "    resized = cv.resize(img,(2500,2500))\n",
    "    height,width,channel = img.shape\n",
    "    print(f\"Image:{img.shape}\")\n",
    "    bbox = annotations_box[annotations_box['image_url']==img_id]\n",
    "    for index,row in bbox.iterrows():\n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "#         xmin = int(xmin*width)\n",
    "#         xmax= int(xmax*width)\n",
    "#         ymin = int (ymin*height)\n",
    "#         ymax = int(ymax*height)\n",
    "        label_name = row['Label_id']\n",
    "        class_series = class_descriptions[class_descriptions['Label_id']==label_name]\n",
    "        class_label_name = class_series['Label_Name']\n",
    "        class_name_changed = list(class_label_name)\n",
    "        class_name = \" \".join(map(str,class_name_changed))\n",
    "        print(class_name)\n",
    "        font = cv.FONT_HERSHEY_COMPLEX\n",
    "        if class_name == 'Building':\n",
    "            print(f\"Coordinates:{xmin,ymin},{xmax,ymax}\")\n",
    "#             cv.rectangle(img,(xmax,ymax),(xmin,ymin),(255,0,0),1)\n",
    "            cv.putText(img,class_name,(xmin,ymin-10),font,0.5,(255,0,0),2)\n",
    "        elif class_name == 'Water':\n",
    "            print(f\"Coordinates:{xmin,ymin},{xmax,ymax}\")\n",
    "            #cv.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),1)\n",
    "            cv.putText(img,class_name,(xmin,ymin-10),font,0.5,(0,0,255),2)\n",
    "        elif class_name == 'Trees':\n",
    "            print(f\"Coordinates:{xmin,ymin},{xmax,ymax}\")\n",
    "#             cv.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),1)\n",
    "            cv.putText(img,class_name,(xmin,ymin-10),font,0.5,(34,139,34),2)\n",
    "        elif class_name == 'Empty Land':\n",
    "            print(f\"Coordinates:{xmin,ymin},{xmax,ymax}\")\n",
    "#             cv.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),1)\n",
    "            cv.putText(img,class_name,(xmin,ymin),font,0.5,(255,255,0),2)\n",
    "            \n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.title(\"Image with Bounding Box\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions['Label_Name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17507fcb",
   "metadata": {},
   "source": [
    "## Partial VGG Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e12ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary modules for VGG Convolution Neural Network\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "# from keras.objectives import categorical_crossentropy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils import generic_utils\n",
    "from keras import initializers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Partial VGG since we do want only the feature map\n",
    "\n",
    "def partial_vgg(input_tensor=None):\n",
    "\n",
    "\n",
    "    input_shape = (544, 509, 3)\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    print(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    print(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    print(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    print(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # We are not using fully connected layers (3 fc layers) as we need feature maps as output from this network.\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f512f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = partial_vgg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c31cb",
   "metadata": {},
   "source": [
    "## Regional Proposal Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Proposal Network\n",
    "\n",
    "def rpn_layer(base_layers, num_anchors):\n",
    " \n",
    "    #cnn_used for creating feature maps: vgg, num_anchors: 9\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(base_layers)\n",
    "    \n",
    "    #classification layer: num_anchors (9) channels for 0, 1 sigmoid activation output\n",
    "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    #regression layer: num_anchors*4 (36) channels for computing the regression of bboxes\n",
    "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear')(x)\n",
    "\n",
    "    return [x_class, x_regr, base_layers] #classification of object(0 or 1),compute bounding boxes, base layers vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1d271",
   "metadata": {},
   "source": [
    "## Taking only the classifier from the RPN Layer not the Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only the classifier not the regressor\n",
    "\n",
    "classifier = rpn_layer(x,9)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7642fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the rank and shape of the classfier\n",
    "\n",
    "class_layer = classifier[0]\n",
    "print(tf.rank(class_layer).name)\n",
    "print(class_layer.shape)\n",
    "# print(type(class_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2829f",
   "metadata": {},
   "source": [
    "(None, 34, 31, 9)\n",
    "It means that there are 9 anchor boxes in which they are in the Foreground Class\n",
    "Since 9 is mentioned in the paper\n",
    "34,31 are the sizes of the number of anchor boxes which are in the foreground classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e8c8d",
   "metadata": {},
   "source": [
    "## ROI Pooling \n",
    "ROI Pooling stands for Region of Interest Pooling which will transform the feature map of different sizes to the feature map of the same sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8eee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoiPoolingConv(Layer):\n",
    "    '''ROI pooling layer for 2D inputs.\n",
    "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
    "    K. He, X. Zhang, S. Ren, J. Sun\n",
    "    # Arguments\n",
    "        pool_size: int\n",
    "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
    "        num_rois: number of regions of interest to be used\n",
    "    # Input shape\n",
    "        list of two 4D tensors [X_img,X_roi] with shape:\n",
    "        X_img:\n",
    "        `(1, rows, cols, channels)`\n",
    "        X_roi:\n",
    "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
    "    # Output shape\n",
    "        3D tensor with shape:\n",
    "        `(1, num_rois, channels, pool_size, pool_size)`\n",
    "    '''\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "\n",
    "        self.dim_ordering = K.image_data_format()\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.nb_channels = input_shape[0][3]   \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "\n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        # x[0] is image with shape (rows, cols, channels)\n",
    "        img = x[0]\n",
    "\n",
    "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = K.shape(img)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for roi_idx in range(self.num_rois):\n",
    "\n",
    "            x = np.array(rois)[roi_idx]\n",
    "            y = np.array(rois)[roi_idx]\n",
    "            w = np.array(rois)[roi_idx]\n",
    "            h = np.array(rois)[roi_idx]\n",
    "            \n",
    "            x = K.cast(x, 'int32')\n",
    "            y = K.cast(y, 'int32')\n",
    "            w = K.cast(w, 'int32')\n",
    "            h = K.cast(h, 'int32')\n",
    "\n",
    "            # Resized roi of the image to pooling size (7x7)\n",
    "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "            outputs.append(rs)\n",
    "                \n",
    "\n",
    "        final_output = K.concatenate(outputs, axis=0)\n",
    "\n",
    "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
    "        # Might be (1, 4, 7, 7, 3)\n",
    "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
    "\n",
    "        # permute_dimensions is similar to transpose\n",
    "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e74767",
   "metadata": {},
   "source": [
    "## Classifier Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130543d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classifier_layer(base_layers,num_rois = 3, nb_classes = 4):\n",
    "    \"\"\"Create a classifier layer\n",
    "    \n",
    "    Args:\n",
    "        base_layers: vgg\n",
    "        input_rois: `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
    "        num_rois: number of rois to be processed in one time (4 in here)\n",
    "\n",
    "    Returns:\n",
    "        list(out_class, out_regr)\n",
    "        out_class: classifier layer output\n",
    "        out_regr: regression layer output\n",
    "    \"\"\"\n",
    "\n",
    "    input_shape = (num_rois,7,7,512)\n",
    "    input_rois = [1,num_rois,4]\n",
    "\n",
    "    pooling_regions = 7\n",
    "\n",
    "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
    "    # num_rois (4) 7x7 roi pooling\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
    "\n",
    "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
    "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
    "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
    "    out = TimeDistributed(Dropout(0.5))(out)\n",
    "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
    "    out = TimeDistributed(Dropout(0.5))(out)\n",
    "\n",
    "    # There are two output layer\n",
    "    # out_class: softmax acivation function for classify the class name of the object\n",
    "    # out_regr: linear activation function for bboxes coordinates regression\n",
    "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), \n",
    "                                name='dense_class_{}'.format(nb_classes))(out)\n",
    "    # note: no regression target for bg class\n",
    "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), \n",
    "                               name='dense_regress_{}'.format(nb_classes))(out)\n",
    "\n",
    "    return [out_class, out_regr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_returned = classifier_layer(x)\n",
    "classifier_out = value_returned[0]\n",
    "print(classifier_out)\n",
    "print(type(classifier_out))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930815a",
   "metadata": {},
   "source": [
    "# Final Outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bbcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_id = \"image_part_008.jpg\"\n",
    "# plot_bbox(img_id)\n",
    "images = list(images_boxable.loc[:,\"file_name\"])\n",
    "for i in images:\n",
    "    plot_bbox(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
